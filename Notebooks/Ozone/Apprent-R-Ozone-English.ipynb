{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Statistical learning scenarios](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Statistical Adaptation of an Ozone Peak Forecasting Model with R <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**: \n",
    "- Exploration and modeling of climate data using R. \n",
    "- The objective is to predict for the next day a possible exceedance of an ozone concentration threshold from a deterministic forecast on a coarse mesh and local climate variables. \n",
    "- Estimation by different methods: [linear](http://wikistat.fr/pdf/st-m-app-select.pdf) or [logistic](http://wikistat.fr/pdf/st-m-app-rlogit.pdf) regression, [discriminant analysis](http://wikistat.fr/pdf/st-m-app-add.pdf), [decision tree](http://wikistat.fr/pdf/st-m-app-cart.pdf), [neural network](http://wikistat.fr/pdf/st-m-app-rn.pdf), [model aggregation](http://wikistat.fr/pdf/st-m-app-agreg.pdf), [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf). \n",
    "- Comparison of [prediction errors](http://wikistat.fr/pdf/st-m-app-risque.pdf) on a test sample and then ROC curves. \n",
    "- Industrialization with the `caret` package and iteration on several test samples to analyze the distribution of the prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning** \n",
    "\n",
    "* This tutorial is divided into 6 sessions / episodes of tutorials synchronized with the machine learning course. \n",
    "* Think about the answers to the questions marked \"**Question**\".\n",
    "* This notebook is completed by the one in Python (to be done _after_, or in parallel) in order to compare the respective performances of the two environments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective, on these data, is to improve the deterministic forecast (MOCAGE), calculated by the services of MétéoFrance, of the ozone concentration in some sampling stations.  It is a problem of \"statistical adaptation\" of a local forecast of too large scale models with the help of other variables also managed by MétéoFrance, but on a smaller scale (temperature, wind strength...). This is a first way to design *IA hybrid* between a deterministic model and a machine learning algorithm. More precisely, two variables can be predicted: either the quantitative concentration of ozone, or the (qualitative) exceedance of a certain threshold set at $150$. In each case, two approaches are considered : either predict the *quantitative concentration* and then deduce the possible exceedance or directly predict the *exceedance*. In the first case, it is first a *regression* while in the second it is a two-class *discrimination* or logistic regression problem. \n",
    "\n",
    "The question is therefore: what are the best methods and strategies to predict the next day's ozone concentration on the one hand and the occurrence of a pollution peak on the other hand.\n",
    "\n",
    "We propose to test different methods: [logistic regression](http://wikistat.fr/pdf/st-m-app-rlogit.pdf), [discriminant analysis](http://wikistat.fr/pdf/st-m-app-add.pdf), [neural network](http://wikistat.fr/pdf/st-m-app-rn.pdf), [decision tree](http://wikistat.fr/pdf/st-m-app-cart.pdf), [tree aggregation](http://wikistat.fr/pdf/st-m-app-agreg.pdf) (bagging, boosting, random forest), [SVM](http://wikistat.fr/pdf/st-m-app-svm.pdf).  The final objective is the comparison of these methods in order to determine the most efficient one to answer the forecasting problem. This requires the implementation of a very strict protocol to ensure a minimum of objectivity for this comparison.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All operations are performed in R with the help of additional libraries that can be downloaded : \n",
    "\n",
    "* Episode 1 : ggplot2, tidyverse, gridExtra, corrplot, FactoMineR, factoextra, glmnet, ggfortify, pROC, \n",
    "* Pour les autres épisodes : mlbench, MASS, boot, class, e1071, rpart, partykit, nnet, ipred, gbm, randomForest, caret, doParallel, xgboost, missForest, Rlof, dbscan, kernlab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python (see the [notebook](https://github.com/wikistat/Apprentissage/blob/master/Pic-ozone/Apprent-Python-Ozone.ipynb)) leads to comparable results but less complete for their interpretation. In particular, the absence of the *DataFrame* type in the scikit-learn library does not allow a fine selection of variables in the usual statistical models. On the other hand, the execution of the Monte Carlo cross-validation is faster in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Episode 1 : Descriptive statistics and linear models </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the necessary libraries\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(gridExtra)\n",
    "library(GGally)\n",
    "library(plotly)\n",
    "library(corrplot)\n",
    "library(reshape2)\n",
    "library(FactoMineR) \n",
    "library(factoextra)\n",
    "library(glmnet) \n",
    "library(ggfortify)\n",
    "library(pROC)\n",
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data were extracted and formatted by the relevant department of Météo France. They are described by the following variables :\n",
    "\n",
    "* **JOUR**: type of day; holiday (1) or not (0) ;\n",
    "* **O3obs**: ozone concentration actually observed the next day at 5 pm local time, often corresponding to the maximum pollution observed;\n",
    "* **MOCAGE**: forecast of this pollution obtained by a deterministic fluid mechanics model (Navier and Stockes equation);\n",
    "* **TEMPE**: temperature forecast by Météo France for the next day at 5 pm;\n",
    "* **RMH2O** : humidity ratio;\n",
    "* **NO2** : nitrogen dioxide concentration;\n",
    "* **NO** : nitrogen monoxide concentration;\n",
    "* **STATION**: observation location: Aix-en-Provence, Rambouillet, Munchhausen, Cadarache and Plan de Cuques;\n",
    "* **WindMOD**: wind strength;\n",
    "* **WindANG**: wind direction. \n",
    "\n",
    "These are \"clean\" data, without missing values, well coded and small in size. They are therefore primarily of an educational nature, as they allow us to use and compare all the regression and supervised classification approaches.\n",
    "\n",
    "**Caution**: Even if the data are of good quality, a preliminary exploratory study is always necessary to become familiar with the data and prepare them for the modeling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-22T09:48:06.646161Z",
     "start_time": "2019-11-22T09:48:06.591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reading the data\n",
    "\n",
    "path <- \"\"\n",
    "ozone <- read.table(paste(path, \"depSeuil.dat\", sep = \"\"),\n",
    "                    sep = \",\", header = TRUE)\n",
    "# First rows of the dataset\n",
    "head(ozone)\n",
    "\n",
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:37.832339Z",
     "start_time": "2019-11-18T09:21:59.889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Changing the type of categorical variables into factors\n",
    "ozone[, \"JOUR\"] <- as.factor(ozone[, \"JOUR\"])\n",
    "ozone[, \"STATION\"] <- as.factor(ozone[, \"STATION\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification in the summary\n",
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unidimensional statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Specify the nature of the different variables. \n",
    "It is necessary to study their distribution. \n",
    "Note the symmetry or not of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(gridExtra)\n",
    "g1<-ggplot(ozone,aes(x=O3obs))+\n",
    "  geom_histogram(aes(y=after_stat(density)))+\n",
    "  geom_density(alpha=.2, col=\"blue\") \n",
    "g2<-ggplot(ozone,aes(x=NO2))+\n",
    "  geom_histogram(aes(y=..density..))+\n",
    "  geom_density(alpha=.2, col=\"blue\") \n",
    "\n",
    "grid.arrange(g1,g2,ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for the other variables\n",
    "g3<-ggplot(ozone,aes(x=MOCAGE))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g4<-ggplot(ozone,aes(x=TEMPE))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g5<-ggplot(ozone,aes(x=RMH2O))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g6<-ggplot(ozone,aes(x=NO))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g7<-ggplot(ozone,aes(x=VentMOD))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "g8<-ggplot(ozone,aes(x=VentANG))+geom_histogram(aes(y=..density..))+geom_density(alpha=.2, col=\"blue\") \n",
    "\n",
    "grid.arrange(g3,g4,g5,g6,g7,g8,ncol=3)\n",
    "rm(g1,g2,g3,g4,g5,g6,g7,g8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation of some  variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations are proposed to make some distributions more symmetric and thus more \"Gaussian\". This is necessary for some future modeling methods (linear), not for all (trees).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone[, \"SRMH2O\"] <- sqrt(ozone[, \"RMH2O\"])\n",
    "ozone[, \"LNO2\"] <- log(ozone[, \"NO2\"])\n",
    "ozone[, \"LNO\"] <- log(ozone[, \"NO\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Check the appropriateness of these transformations and then remove the initial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ozone <- ozone[, c(1:4, 8:13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build the `DepSeuil` threshold variable to get the file that will actually be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozone[, \"DepSeuil\"] <- as.factor(ozone[, \"O3obs\"] > 150)\n",
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations of the  variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What about the relationship of the variables 2 to 2 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggpairs(ozone[, c(2:4, 6:10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Complete by visualizing the correlations with the `corrplot()` function (package `corrplot`). What is the limitation of this type of numerical diagnosis : which type of correlation is measured? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(corrplot)\n",
    "corrplot(cor(ozone[, c(2:4, 6:10)]),method=\"ellipse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Principal Components Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commands allow to perform a [principal component analysis](http://wikistat.fr/pdf/st-m-explo-acp.pdf) (PCA) on the quantitative variables only. Moreover, the variable to be modeled (O3obs, observed concentration) is not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced PCA\n",
    "library(FactoMineR)\n",
    "acp <- PCA(ozone[, c(11,2:4, 6:10)], scale.unit = TRUE,\n",
    "           graph = FALSE, quali.sup = 1, quanti.sup = 2, ncp = 7)\n",
    "# Eigenvalue decay\n",
    "library(factoextra)\n",
    "g1<-fviz_eig(acp, addlabels = TRUE, ylim = c(0, 40))\n",
    "library(reshape2)\n",
    "g2<-ggplot(melt(acp$ind$coord),aes(x=Var2,y=value))+\n",
    "  geom_boxplot()+\n",
    "  xlab(\"\")\n",
    "grid.arrange(g1,g2,ncol=2)\n",
    "# \n",
    "library(corrplot)\n",
    "corrplot(acp$var$cor, is.corr=FALSE,method=\"ellipse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_pca_var(acp)\n",
    "fviz_pca_ind(acp,col.ind=\"contrib\",label=\"none\",gradient.cols = c(\"white\", \"#2E9FDF\", \"#FC4E07\" ))\n",
    "fviz_pca_var(acp,axes=c(1,3))\n",
    "fviz_pca_ind(acp,col.ind=\"contrib\",label=\"none\",gradient.cols = c(\"white\", \"#2E9FDF\", \"#FC4E07\" ),axes=c(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What do these different graphs represent?\n",
    "\n",
    "**Question** What about the choice of the number of dimensions, the atypical values?\n",
    "\n",
    "**Question** What about the correlation structure of the variables? Is it intuitive?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same graph by coloring according to the threshold exceedance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fviz_pca_ind(acp, label=\"none\", habillage=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is therefore to define a surface separating the two classes. \n",
    "\n",
    "**Question** Does a linear discrimination (hyperplane) seem possible? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not useful here but an unsupervised classification is easy to obtain. For example in 2 classes, by the K-means algorithm. Does it give the same information? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.ozone <- kmeans(ozone[, c(3:4, 6:10)], centers = 2)\n",
    "# Representation in the coordinates of the PCA\n",
    "acp2 <- PCA(cbind(clus = as.factor(km.ozone$cluster),\n",
    "          ozone[, c(11, 3:4, 6:10)]), scale.unit = TRUE,\n",
    "          graph = FALSE, quali.sup = 1:2, ncp = 7)\n",
    "fviz_pca_ind(acp2, label=\"none\", habillage=\"clus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search for a better prediction method follows the following protocol.\n",
    "\n",
    "1. Preliminary uni- and multidimensional descriptive steps to identify inconsistencies, non-significant or exotic distribution variables, irrelevant or atypical individuals... and to study the data structures. It can also be the long step of building specific variables, attributes or *features* of the data. \n",
    "2. Randomly draw a *test* sample that will only be used in the *last step* of comparing methods.\n",
    "3. The remaining part is the *training* sample for estimating the parameters of the models.\n",
    "4. For each of the methods, optimize the complexity of the models by minimizing an \"unbiased\" estimate of the prediction error, e.g., by [*cross validation*](http://wikistat.fr/pdf/st-m-app-risque.pdf):\n",
    "    - Variables and interactions to be considered in linear or logistic regression;\n",
    "    - variables and method for discriminant analysis;\n",
    "    - number of leaves in the regression or classification tree;\n",
    "    - architecture (number of neurons, penalization) of the perceptron;\n",
    "    - aggregation algorithm, \n",
    "    - kernel and penalization of SVMs.\n",
    "5.  Comparison of predictive qualities based on the misclassification rate for the  test sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In the case of a relatively \"small\" sample, it is recommended to iterate the learning set /test set splitting procedure, in order to reduce the (average) variance of the risk estimates.\n",
    "\n",
    "**Question** How is this specific cross-validation procedure called ? \n",
    "\n",
    "* *Beware*: do not \"cheat\" by modifying the model obtained in the previous step in order to improve the result on the test sample!\n",
    "* The criterion used depends on the problem: squared error, misclassification rate, cross-entropy, AUC (area under the ROC curve) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands below perform the extraction of the subset of the training and test data. \n",
    "\n",
    "Use three random numbers, and **replace** \"111\" below, for the initialization of the random generator. Be aware that each participant draws a different sample, so it is normal not to get exactly the same results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:39.945357Z",
     "start_time": "2019-11-18T09:22:02.486Z"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(111) # initialization of the generator\n",
    "# Extraction of the samples\n",
    "test.ratio <- .2   # ratio of test sample\n",
    "npop <- nrow(ozone) # number of lines in the data\n",
    "nvar <- ncol(ozone) # number of columns\n",
    "# size of the test sample\n",
    "ntest <- ceiling(npop * test.ratio) \n",
    "# indices of the test sample\n",
    "testi <- sample(1:npop, ntest)\n",
    "# indices of the training sample\n",
    "appri <- setdiff(1:npop, testi) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction of the samples for the regression : ozone concentration prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:39.976151Z",
     "start_time": "2019-11-18T09:22:02.695Z"
    }
   },
   "outputs": [],
   "source": [
    "# construction of the training sample\n",
    "datappr <- ozone[appri, -11] \n",
    "# construction of the test sample\n",
    "datestr <- ozone[testi, -11] \n",
    "# verification\n",
    "str(datappr)\n",
    "str(datestr)\n",
    "#summary(datappr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction of the samples for the classification : prediction of threshold overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:40.000864Z",
     "start_time": "2019-11-18T09:22:02.905Z"
    }
   },
   "outputs": [],
   "source": [
    "# construction of the training sample\n",
    "datappq <- ozone[appri,-2]\n",
    "# construction of the test sample\n",
    "datestq <- ozone[testi,-2] \n",
    "\n",
    "# verification\n",
    "str(datappq)\n",
    "str(datestq)\n",
    "#summary(datappq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We have here \"manually\" done the construction of the samples for pedagogical purposes. In practice, one can use R functions that do this work, in particular the `createDataPartition` function of the `caret` library. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, before moving on to the different algorithms, let's define a function plotting the graph of the residuals with fixed colors and scales on the axes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gplot.res <- function(x, y, titre = \"titre\"){\n",
    "    ggplot(data.frame(x=x, y=y),aes(x,y))+\n",
    "    geom_point(col = \"blue\")+xlim(0, 250)+ylim(-150, 150)+\n",
    "    ylab(\"Résidus\")+ xlab(\"Valeurs prédites\")+\n",
    "    ggtitle(titre)+\n",
    "    geom_hline(yintercept = 0,col=\"green\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Prediction by linear Gaussian model](http://wikistat.fr/pdf/st-m-app-select.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model to be tested is a simple linear Gaussian model but, as some variables are qualitative, it is an analysis of covariance. On the other hand, we are interested in knowing if interactions are to be taken into account. The model then becomes polynomial of order 2 or quadratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear model integrates categorical variables; it is in this case an *analysis of covariance* estimated by the `aov` function better adapted to this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:40.107560Z",
     "start_time": "2019-11-18T09:22:03.699Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimation of the model without interaction\n",
    "reg.lm <-aov(O3obs ~ . , data = datappr)\n",
    "# Extraction of residuals and fitted values from this model\n",
    "res.lm <- reg.lm$residuals\n",
    "fit.lm <- reg.lm$fitted.values\n",
    "# Graph of the residuals\n",
    "gplot.res(fit.lm,res.lm,\"ANCOVA sans sélection de variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What about the distribution of these residuals? \n",
    "\n",
    "**Question** The shape of the cloud gives information about the assumptions of linearity and homoscedasticity of the model. What about the validity of this model?\n",
    "\n",
    "Nevertheless, assess its significance by the following command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:40.123527Z",
     "start_time": "2019-11-18T09:22:03.902Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(reg.lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(reg.lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** This first model is compared with that of the only deterministic forecast MOCAGE. What can we conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:40.226000Z",
     "start_time": "2019-11-18T09:22:04.102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Residuals plot of the deterministic model MOCAGE\n",
    "g1<-gplot.res(datappr[, \"MOCAGE\"],datappr[, \"O3obs\"]-datappr[, \"MOCAGE\"], \"linéaire, MOCAGE seul\")\n",
    "\n",
    "g2<-gplot.res(fit.lm, res.lm, \"Linéaire, sans sélection\")\n",
    "grid.arrange(g1,g2,ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable selection with  L1 regularisation (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "# with quantitatives variables only\n",
    "reg.lasso.quanti <- glmnet(y = datappr[, 2],\n",
    "                           x = as.matrix(datappr[, -c(1, 2, 5)]))\n",
    "# with all the variables, create first the matrix of experiments \n",
    "# with 'model.matrix' (remember to remove the intercept from the model)\n",
    "x.mat <- model.matrix(O3obs ~ . - 1, data = datappr)\n",
    "reg.lasso <- glmnet(y = datappr$O3obs, x = x.mat)\n",
    "options(repr.plot.width = 12, repr.plot.height = 10)\n",
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE)\n",
    "legend(\"topright\", \n",
    "       legend = paste(1:ncol(x.mat), \" - \", colnames(x.mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What does the model.matrix command do? How are the categorical variables handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model.matrix)\n",
    "head(x.mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What do the above curves, called \"regularization paths\", represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then focus on the choice of the regularization parameter by cross-validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.lasso.cv <- cv.glmnet(y = datappr[, 2], x = x.mat)\n",
    "#plot(reg.lasso.cv)\n",
    "autoplot(reg.lasso.cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "help(cv.glmnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What do the bold dots represent? What about the band around them? \n",
    "\n",
    "**Question** How are the log(lambda) values corresponding to the vertical dotted lines obtained?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated value\n",
    "paste(\"CV estimate of lambda :\", round(reg.lasso.cv$lambda.1se, 3))\n",
    "# corresponding model\n",
    "coef(reg.lasso.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** How many non-zero coefficients are left. Check on the regularization paths.\n",
    "\n",
    "**Question** Same question by choosing the other value of lambda retained by glmnet, i.e. `reg.lasso.cv$lambda.min`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE,xlim=c(0,2),ylim=c(-2,5))\n",
    "abline(v=log(reg.lasso.cv$lambda.1se),col=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated value\n",
    "paste(\"CV estimate of lambda :\", round(reg.lasso.cv$lambda.min, 3))\n",
    "# corresponding model\n",
    "coef(reg.lasso.cv, s = \"lambda.min\")\n",
    "\n",
    "plot(reg.lasso, xvar = \"lambda\", label = TRUE,xlim=c(-2,0),ylim=c(-5,40))\n",
    "abline(v=log(reg.lasso.cv$lambda.min),col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the residuals against the predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of fitted values and residuals\n",
    "\n",
    "fit.lasso <- predict(reg.lasso.cv, s = \"lambda.min\", newx = x.mat)\n",
    "res.lasso <- datappr$O3obs - fit.lasso\n",
    "\n",
    "fit.lasso.1se <- predict(reg.lasso.cv, s = \"lambda.1se\", newx = x.mat)\n",
    "res.lasso.1se <- datappr$O3obs - fit.lasso.1se \n",
    "\n",
    "# Graph of the residuals\n",
    "options(repr.plot.width = 12, repr.plot.height = 4)\n",
    "par(mfrow = c(1, 3))\n",
    "gplot.res(fit.lm, res.lm, \"Linéaire, sans sélection\")\n",
    "gplot.res(fit.lasso, res.lasso, \"Linéaire, pénalité L1, lambda min\")\n",
    "gplot.res(fit.lasso.1se, res.lasso.1se, \"Linéaire, pénalité L1, lambda 1se\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Comment. \n",
    "\n",
    "**Question** Calculate the MSE criterion (mean square of residuals) for the two models. Why is the one obtained by LASSO worse? Which criterion does LASSO minimize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paste(\"Modèle linéaire sans sélection:\",mean(res.lm^2))\n",
    "paste(\"LASSO avec lambda.min:\",mean(res.lasso^2))\n",
    "paste(\"LASSO avec lambda.1se:\",mean(res.lasso.1se^2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Estimate the error of the simple linear model without variable selection by cross validation. Compare with the LASSO error. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V=10 ; nV=floor(nrow(datappr)/V)\n",
    "S=sample(1:nrow(datappr),replace=FALSE)\n",
    "error.CV = c()\n",
    "for(v in 1:V)\n",
    "{  #\n",
    "    datappr.learn=datappr[-c(S[(nV*(v-1)):(nV*v)]),] \n",
    "    datappr.valid=datappr[c(S[(nV*(v-1)):(nV*v)]),]\n",
    "    error.CV=c(error.CV,mean((datappr.valid$O3obs-predict(aov(O3obs ~ ., data=datappr.learn),newdata=datappr.valid))^2))\n",
    "}\n",
    "mean(error.CV)\n",
    "\n",
    "print(reg.lasso.cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following study implements all the second-order interactions between the variables. It is therefore a quadratic regression model. It is estimated with the function `glm()` which allows an automatic model selection. The backward method is used but the stepwise method could also be used. This type of procedure is not implemented in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable selection with AIC criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward selection : at each step, each model is compared to all possible sub-models obtained by deleting one of the interactions or one of the variables, provided that it is not present in an interaction. The selected and deleted variable is the one that decreases the most the considered criterion: AIC (*Akaïke Information Criterion*). \n",
    "\n",
    "**Question** Which other criterion, equivalent to AIC in the Gaussian case and of known residual variance, is used in linear regression? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.291201Z",
     "start_time": "2019-11-18T09:22:04.508Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model estimation  with all interactions  of order 2\n",
    "reg.glm <- glm(O3obs ~ .^2, data = datappr)\n",
    "# Search for the best model in the sense \n",
    "# of the Akaïke criterion by backward method\n",
    "reg.glm.step <- step(reg.glm, direction = \"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.497378Z",
     "start_time": "2019-11-18T09:22:04.515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Coefficients  of the model\n",
    "anova(reg.glm.step, test = \"F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable selection by L1 regularisation  (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with a quadratic model with L1 penalty\n",
    "x.mat2 <- model.matrix(O3obs ~ .^2 - 1, data = datappr)\n",
    "reg.lasso2.cv <- cv.glmnet(y = datappr[, \"O3obs\"], x = x.mat2)\n",
    "coef(reg.lasso2.cv, s = \"lambda.1se\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.635351Z",
     "start_time": "2019-11-18T09:22:04.520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extraction of fitted values and residuals\n",
    "fit.glm <- reg.glm.step$fitted.values\n",
    "res.glm <- reg.glm.step$residuals\n",
    "fit.lasso2 <- predict(reg.lasso2.cv, s = \"lambda.min\", newx = x.mat2)\n",
    "res.lasso2 <- datappr$O3obs - fit.lasso2\n",
    "\n",
    "# Graph of the residuals\n",
    "g1<-gplot.res(fit.lm, res.lm, \"linéaire\")\n",
    "g2<-gplot.res(fit.lasso, res.lasso, \"linéaire, pénalité L1\")\n",
    "g3<-gplot.res(fit.glm, res.glm, \"quadratique, backward AIC\")\n",
    "g4<-gplot.res(fit.lasso2, res.lasso2, \"quadratique, pénalité L1\")\n",
    "grid.arrange(g1,g2,g3,g4,ncol=2,nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We notice that the presence of some interactions or variables are relevant according to the Akaïke criterion but not significant according to the Fisher test. This presence in the model could be more finely analyzed by considering an estimate of the error by cross-validation. The idea would be to remove one by one the least significant variables or interactions to see how the cross-validation behaves. On the other hand, if the stepwise procedure leads to a different model, the estimation of the error by cross-validation also allows to optimize the choice.\n",
    " \n",
    "These refinements are not efficient on these data. The model obtained by minimizing the AIC criterion is kept.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"optimal\" model obtained by the backward  method is used to predict the test sample and thus to estimate, without bias, a prediction error. Two errors are estimated : the first one is the quadratic one for the regression while the second one is derived from the confusion matrix which crosses the predicted threshold overflows with those actually observed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.652288Z",
     "start_time": "2019-11-18T09:22:05.132Z"
    }
   },
   "outputs": [],
   "source": [
    "# Computation of forecasts for the quadratic backward model AIC\n",
    "pred.glm <- predict(reg.glm.step, newdata = datestr)\n",
    "# Mean squared error of prediction (MSE)\n",
    "sum((pred.glm - datestr[, \"O3obs\"])^2) / nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.669514Z",
     "start_time": "2019-11-18T09:22:05.139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Quadratic error for MOCAGE\n",
    "sum((datestr[,\"MOCAGE\"] - datestr[,\"O3obs\"])^2) / nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification error  (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.689237Z",
     "start_time": "2019-11-18T09:22:05.144Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for threshold exceedance prediction\n",
    "table(pred.glm > 150, datestr[, \"O3obs\"] > 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.714261Z",
     "start_time": "2019-11-18T09:22:05.150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for the prediction of \n",
    "# threshold exceedance by MOCAGE\n",
    "table(datestr[, \"MOCAGE\"] > 150, datestr[, \"O3obs\"] > 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note these errors for comparison with those obtained by the other methods. Note the asymmetry of the errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Binomial Model Prediction](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)\n",
    "\n",
    "Rather than predicting the concentration and then the exceedance, we can ask ourselves if it would not be relevant to directly predict the presence or absence of an exceedance. Since the variable to be modeled is binary, logistic regression will be used. As for regression, different model selection strategies can be used and compared before estimating the prediction error on the test sample.\n",
    "\n",
    "### Logistic regression without interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:44.819132Z",
     "start_time": "2019-11-18T09:22:05.557Z"
    }
   },
   "outputs": [],
   "source": [
    "# estimation of the complete model\n",
    "log.lm <- glm(DepSeuil ~. , data = datappq, family = binomial)\n",
    "# significance of the parameters\n",
    "anova(log.lm, test = \"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:45.012876Z",
     "start_time": "2019-11-18T09:22:05.564Z"
    }
   },
   "outputs": [],
   "source": [
    "# Search for an optimal model in the sense of Akaïke\n",
    "log.lm.step <- step(log.lm, direction = \"backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:45.052862Z",
     "start_time": "2019-11-18T09:22:05.570Z"
    }
   },
   "outputs": [],
   "source": [
    "# Obtained Model\n",
    "anova(log.lm.step, test = \"Chisq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:45.074743Z",
     "start_time": "2019-11-18T09:22:05.576Z"
    }
   },
   "outputs": [],
   "source": [
    "# confusion matrix of the training sample and  training error\n",
    "table(log.lm.step$fitted.values > 0.5, datappq[, \"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With so many variables and interactions, and therefore parameters, the estimation of the complete logistic regression model encounters problems and displays *warnings* because some well-fitted probabilities (0 or 1) cause divisions by 0. Here a *forward* or better *stepwise* procedure for selecting the variables and interactions leads to reasonable results. A method with L1 penalization can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.096169Z",
     "start_time": "2019-11-18T09:22:05.997Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "log.qm <- glm(DepSeuil ~ 1, data = datappq,family = binomial)\n",
    "#  stepwise algorithm  \n",
    "log.qm.step1 <- step(log.qm, direction = \"both\",\n",
    "    scope = list(lower = ~1, upper = ~(JOUR + MOCAGE + TEMPE + \n",
    "            STATION + VentMOD + VentANG + LNO2 + LNO + SRMH2O)^2), \n",
    "    family=binomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.158081Z",
     "start_time": "2019-11-18T09:22:06.003Z"
    }
   },
   "outputs": [],
   "source": [
    "anova(log.qm.step1, test = \"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.179001Z",
     "start_time": "2019-11-18T09:22:06.010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction by the quadratic model\n",
    "pred.log <- predict(log.qm.step1, newdata = datestq, type = \"response\")\n",
    "# Confusion matrix\n",
    "table(pred.log > 0.5, datestq[, \"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the previous approach. Save the results for comparison with other methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ROC curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to construct a ROC curve in association with the prediction obtained from a Gaussian linear model. Indeed, the variation of the theoretical threshold of overtaking (150) will vary the respective proportions of the true and false positive rates. This is the same as varying the threshold of a \"proba\" for the forecast values divided by 300.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 6, repr.plot.height = 6)\n",
    "par(mfrow = c(1, 1))\n",
    "rocmocage <- datestr[,  \"MOCAGE\"] / 300 \n",
    "DepSeuil=c(datestr[, \"O3obs\"] > 150)\n",
    "predmocage <- prediction(rocmocage,DepSeuil)\n",
    "perfmocage <- performance(predmocage, \"tpr\", \"fpr\")\n",
    "\n",
    "\n",
    "rocglm <- pred.glm / 300    \n",
    "predglm <- prediction(rocglm,DepSeuil)\n",
    "perfglm <- performance(predglm, \"tpr\", \"fpr\")\n",
    "\n",
    "roclogit <- predict(log.qm.step1, newdata = datestq, type=\"response\")\n",
    "predlogit <- prediction(roclogit, datestq[, \"DepSeuil\"])\n",
    "perflogit <- performance(predlogit, \"tpr\", \"fpr\")\n",
    "\n",
    "plot(perfglm, col = \"blue\",lty=2, main = \"Courbe ROC \\n Mod. quad. backward AIC \")\n",
    "plot(perfmocage,col=\"orange\",lty=2,add=TRUE)\n",
    "plot(perflogit,col=\"green\",lty=1,add=TRUE) \n",
    "\n",
    "legend(\"right\", legend=c(\"Mod. Quad. backward AIC\", \"Mocage\", \"Logit\"),\n",
    "       col=c(\"blue\",\"orange\",\"green\"), lty=c(2,2,1), text.font=1,    cex=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What are sensitivity and specificity of a ROC curve?\n",
    "\n",
    "The results obtained obviously depend in addition on the initial sampling between training and test. In the case where the curves cross, it means that there is no uniformly better prediction of the occurrence of treshold overflow. This depends on the sensitivity or specificity chosen for the model. This underlines the importance of the correct definition of the criterion to be used for the choice of a \"best\" method. This choice depends directly on the \"political\" or \"economic\" choice of sensitivity and/or specificity of the chosen model. In other words, what false alarm rate, with obvious economic implications, is bearable with respect to the undetected exceedances and thus the health degradation of the population at risk?\n",
    " \n",
    "Once this choice has been made, the statistician can make a comparison of the methods involved.\n",
    "\n",
    "**Question** Are the performances of the two Gaussian and binomial approaches very different?\n",
    "\n",
    "**Question** On the graph above, add the ROC curve for the deterministic MOCAGE model. What do you observe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Episode 2 : Discriminant Analysis, KNN, SVM </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Discriminant Analysis](http://wikistat.fr/pdf/st-m-app-add.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The objective is to compare the three discriminant analysis methods available in R: linear parametric `lda` (homoscedasticity), quadratic parametric `qda` (heteroscedasticity) under Gaussian assumption and non-parametric $K$ nearest neighbors.\n",
    " \n",
    "**Question** Which assignment criterion is used in LDA?\n",
    "\n",
    "**Question** What do the homoscedasticity or heteroscedasticity assumptions mean?\n",
    "\n",
    "**Question** Which function is estimated \"non-parametrically\" by the $K$ nearest neighbors algorithm?\n",
    " \n",
    "*Note*: these techniques only accept quantitative explanatory or predictive variables. Nevertheless, a qualitative variable with two modalities, for example the type of day, can be considered as quantitative in the form of an indicator function taking its values in $\\{0, 1\\}$. In this last case, one should not try to interpret the discrimination functions, just consider prediction errors. The *Station* variable is not taken into account.\n",
    "\n",
    "The standard R library `MASS` for discriminant analysis does not propose an automatic procedure for choosing a variable, but in this example, the variables are few.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.294675Z",
     "start_time": "2019-11-18T09:22:07.823Z"
    }
   },
   "outputs": [],
   "source": [
    "library(MASS) # \n",
    "library(class) #  for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.341174Z",
     "start_time": "2019-11-18T09:22:07.829Z"
    }
   },
   "outputs": [],
   "source": [
    "# linear discriminant analysis\n",
    "disc.lda=lda(DepSeuil~.,data=datappq[,-4]) \n",
    "# quadratic discriminant analysis\n",
    "disc.qda=qda(DepSeuil~.,data=datappq[,-4]) \n",
    "# k nearest neighbours\n",
    "disc.knn=knn(datappq[,c(-4,-10)],datappq[,c(-4,-10)],datappq$DepSeuil,k=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the lack of homogeneity of R commands from different libraries. The negative column index ($-10$) allows to remove the column containing the variable to be predicted of type factor. This one is mentioned in the third parameter for the training data. The [caret library](http://topepo.github.io/caret/index.html) circumvents these difficulties by encompassing all the training libraries and homogenizing the calls for model estimation and prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "lda.fit<-train(DepSeuil~.,data=datappq[,-4],method=\"lda\")\n",
    "qda.fit<-train(DepSeuil~.,data=datappq[,-4],method=\"qda\")\n",
    "knn.fit<-train(DepSeuil~.,data=datappq[,-4],method=\"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of the prediction error by cross-validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without the use of the `caret` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.362843Z",
     "start_time": "2019-11-18T09:22:08.228Z"
    }
   },
   "outputs": [],
   "source": [
    "# cross-validation error for linear discriminant analysis\n",
    "disc.lda=lda(DepSeuil~.,data=datappq[,-4],CV=T) \n",
    "# estimate the error rate from the confusion matrix\n",
    "table(datappq[,\"DepSeuil\"],disc.lda$class)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.385631Z",
     "start_time": "2019-11-18T09:22:08.238Z"
    }
   },
   "outputs": [],
   "source": [
    "#  quadratic discriminant analysis\n",
    "disc.qda=qda(DepSeuil~.,data=datappq[,-4],CV=T)  \n",
    "table(datappq[,\"DepSeuil\"],disc.qda$class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Knn, the choice of the number of neighbors $K$ has to be optimized by cross-validation but the procedure proposed by the `class` library is the *leave-one-out* one, so it is too computationally expensive for large files. It would be easy to program it but the `e1071` library already proposes several cross-validation functions for many discrimination techniques. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:46.922719Z",
     "start_time": "2019-11-18T09:22:08.551Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimisation of  the number of neighbours in KNN\n",
    "library(e1071)\n",
    "plot(tune.knn(as.matrix(datappq[,c(-4,-10)]),as.factor(datappq[,10]),k=2:20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Which cross-validation procedure is executed by default by the `tune()` function?\n",
    "\n",
    "**Question** Run several successive executions of this \"optimization\". Why does the value of $K$ differ at each run? How to choose $K$ ?\n",
    "\n",
    "**Question** Compare with the previous errors estimated also by cross-validation. Which discriminant analysis should be used? Why ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the  `caret` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation with 10 folds\n",
    "param_train<-trainControl(method=\"cv\",number=10)\n",
    "# cross-validation error for linear discriminant analysis\n",
    "lda.fit <- train(DepSeuil~.,data=datappq[,-4],method=\"lda\",trControl=param_train)\n",
    "#  estimate the error rate from the confusion matrix\n",
    "table(datappq[,\"DepSeuil\"],predict(lda.fit,datappq[,-c(4,10)])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation error for quadratic discriminant analysis\n",
    "qda.fit <- train(DepSeuil~.,data=datappq[,-4],method=\"qda\",trControl=param_train)\n",
    "# estimate the error rate from the confusion matrix\n",
    "table(datappq[,\"DepSeuil\"],predict(qda.fit,datappq[,-c(4,10)])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross-validation error for kNN\n",
    "knn.fit <- train(DepSeuil~.,data=datappq[,-4],method=\"knn\",trControl=param_train,tuneLength=20)\n",
    "#  estimate the error rate from the confusion matrix\n",
    "table(datappq[,\"DepSeuil\"],predict(knn.fit,datappq[,-c(4,10)])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commands calculate the confusion matrix on the test dataset for each cross-validation optimized discriminant analysis method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LDA\n",
    "table(predict(lda.fit,datestq[,-4]),datestq[,\"DepSeuil\"])\n",
    "sum(predict(lda.fit,datestq[,-4])!=datestq[,\"DepSeuil\"])/nrow(datestq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QDA\n",
    "table(predict(qda.fit,datestq[,-4]),datestq[,\"DepSeuil\"])\n",
    "sum(predict(qda.fit,datestq[,-4])!=datestq[,\"DepSeuil\"])/nrow(datestq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  KNN\n",
    "table(predict(knn.fit,datestq[,-4]),datestq[,\"DepSeuil\"])\n",
    "sum(predict(knn.fit,datestq[,-4])!=datestq[,\"DepSeuil\"])/nrow(datestq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also use the function `confusionMatrix()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusionMatrix(predict(knn.fit,datestq[,-4]),datestq[,\"DepSeuil\"],positive=\"TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will compare via the ROC curve the discriminant analysis methods LDA, QDA, KNN and logistic regression (see Episode 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression from Episode 1 \n",
    "log.qm <- glm(DepSeuil ~ 1, data = datappq,family = binomial)\n",
    "log.qm.step1 <- step(log.qm, direction = \"both\",\n",
    "    scope = list(lower = ~1, upper = ~(JOUR + MOCAGE + TEMPE + \n",
    "            STATION + VentMOD + VentANG + LNO2 + LNO + SRMH2O)^2), \n",
    "    family=binomial,trace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(pROC)\n",
    "rocobjlda<-roc(datestq$DepSeuil,predict(lda.fit,datestq[,-4],type=\"prob\")[,2])\n",
    "rocobjqda<-roc(datestq$DepSeuil,predict(qda.fit,datestq[,-4],type=\"prob\")[,2])\n",
    "rocobjknn<-roc(datestq$DepSeuil,predict(knn.fit,datestq[,-4],type=\"prob\")[,2])\n",
    "rocobjlogit<-roc(datestq[, \"DepSeuil\"],predict(log.qm.step1, newdata = datestq, type=\"response\"))\n",
    "\n",
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "ggroc(list(lda=rocobjlda,qda=rocobjqda,knn=rocobjknn,logit=rocobjlogit),legacy.axes=T)+\n",
    "  xlab(\"False Positive Rate\")+\n",
    "  ylab(\"True Positive Rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Is a method uniformly better on this test sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Support Vector Machine (SVM)](http://wikistat.fr/pdf/st-m-app-svm.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Introduction\n",
    "Despite the theoretical guarantees concerning this type of algorithm, the results depend strongly on the choice of parameters. We will first limit ourselves to the Gaussian kernel (default choice); the function `tune.svm` allows to easily test several situations by estimating the prediction quality by cross-validation on a grid. The execution time in R is a bit long... \n",
    "\n",
    "**Question** Is the execution time for SVM more sensitive to the number of observations or to the number of variables? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "Although initially developed in the case of a binary variable, SVMs have been extended to regression problems. The estimation and optimization of the penalty coefficient are obtained by the following commands.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "help(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.reg0 = svm(O3obs ~ ., data = datappr)\n",
    "summary(svm.reg0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set.seed(2021)\n",
    "svm.reg.tune = tune.svm(O3obs ~ ., data = datappr, cost = c(1, 1.5, 2, 2.5, 3, 3.5), \n",
    "    gamma = seq(0.02, 0.1, by = 0.02))\n",
    "plot(svm.reg.tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the penalty (cost) is 1.\n",
    "\n",
    "**Question** Note the optimal penalty for the considered kernel (Gaussian). Re-estimate the supposedly optimal model before plotting the residuals. As before, observe that several runs lead to different results and thus that the optimization of this parameter is tricky to say the least.\n",
    "\n",
    "**Question** What other kernels are available in this implementation of SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.reg = svm(O3obs ~ ., data = datappr, cost = svm.reg.tune$best.parameters$cost, \n",
    "    gamma = svm.reg.tune$best.parameters$gamma)\n",
    "summary(svm.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation and graph of the residuals\n",
    "fit.svmr=fit.svmr=svm.reg$fitted\n",
    "res.svmr=fit.svmr-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.svmr,res.svmr,titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the \"corridor\" effect on the residuals. \n",
    "\n",
    "**Question** What causes the residuals to move closer together in a \"corridor\"? What do you observe when you vary the cost and epsilon parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisation\n",
    "svm.dis.tune = tune.svm(DepSeuil ~ ., data = datappq, cost = c(1,1.25,1.5,1.75,2), \n",
    "    gamma = seq(0.02, 0.1, by = 0.02))\n",
    "plot(svm.dis.tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "svm.dis.tune$best.parameters\n",
    "svm.dis=svm(DepSeuil~.,data=datappq,cost = svm.reg.tune$best.parameters$cost, \n",
    "    gamma = svm.reg.tune$best.parameters$gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the test sample\n",
    "#### Regression error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.svmr=predict(svm.reg,newdata=datestr)\n",
    "# Mean squared error of prediction\n",
    "sum((pred.svmr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Classification error (confusion matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for prediction of threshold overflow (regression)\n",
    "table(pred.svmr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for discrimination\n",
    "pred.svmq=predict(svm.dis,newdata=datestq)\n",
    "table(pred.svmq,datestq[,\"DepSeuil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocsvmr = pred.svmr/300\n",
    "predsvmr = prediction(rocsvmr, datestq$DepSeuil)\n",
    "perfsvmr = performance(predsvmr, \"tpr\", \"fpr\")\n",
    "\n",
    "# re-estimate the model to obtain the probabilities \n",
    "svm.dis = svm(DepSeuil ~ ., data = datappq, cost = 1.25, probability = TRUE)\n",
    "pred.svmq = predict(svm.dis, newdata = datestq, probability = TRUE)\n",
    "rocsvmq = attributes(pred.svmq)$probabilities[, 2]\n",
    "predsvmq = prediction(rocsvmq, datestq$DepSeuil)\n",
    "perfsvmq = performance(predsvmq, \"tpr\", \"fpr\")\n",
    "\n",
    "plot(perflogit, col = \"blue\")\n",
    "plot(perfsvmr, col = \"red\", lty = 2, add = TRUE)\n",
    "plot(perfsvmq, col = \"green\", add = TRUE)\n",
    "\n",
    "\n",
    "legend(\"right\", legend=c(\"Logit\",\"SVR\", \"SVM\"),\n",
    "       col=c(\"blue\",\"red\",\"green\"), lty=c(1,2,1), text.font=1,    cex=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Do SVMs bring an improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Episode 3 :  CART, Agreggation of models  </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Binary decision tree](http://wikistat.fr/pdf/st-m-app-cart.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `rpart` library is the most commonly used for the construction of decision trees. Two types of trees can be estimated depending on whether the variable to be modeled is the ozone concentration (regression tree) or directly the threshold overflow (discrimination or decision tree). Different parameters control the execution of the algorithm: the minimum penalty (cp) for the construction of the maximum tree, the minimum number of observations per node, the number of cross-validations (by default 10)... see the online help (`?rpart.control`) for more details but it is not very explicit on some parameters.\n",
    "\n",
    "NB. A sequence of values of the `cp` penalty is associated to a sequence of nested trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation and pruning of the regression tree\n",
    "**Question** Which criterion is optimized when creating a node in the tree?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.088662Z",
     "start_time": "2019-11-18T09:22:10.466Z"
    }
   },
   "outputs": [],
   "source": [
    "library(rpart) \n",
    "help(rpart)\n",
    "help(rpart.control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.reg=rpart(O3obs~.,data=datappr,control=rpart.control(cp=0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command `summary(tree.reg)` provides a description of the resulting tree but a graph is preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.181644Z",
     "start_time": "2019-11-18T09:22:10.473Z"
    }
   },
   "outputs": [],
   "source": [
    "library(rpart.plot)\n",
    "options(repr.plot.width = 15, repr.plot.height = 10)\n",
    "rpart.plot(tree.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tree is unreadable and has too many leaves for a good prediction (overlearning), it is necessary to reduce the number by pruning. The following commands compute the predictions obtained by 10-fold cross-validation for each pruned tree according to the successive values of the complexity coefficient. The sequence of these values is implicitly the one provided by `rpart`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.218915Z",
     "start_time": "2019-11-18T09:22:10.686Z"
    }
   },
   "outputs": [],
   "source": [
    "help(xpred.rpart)\n",
    "xmat<-xpred.rpart(tree.reg,xval=10) \n",
    "# one row for each observation and one column for each complexity value\n",
    "\n",
    "# Cross-validation error by CP value\n",
    "CVerr<-apply((xmat-datappr[,\"O3obs\"])^2,2,sum)\n",
    "\n",
    "plotcp(tree.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the value of `cp` corresponding to the smallest error and use it to build the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.236505Z",
     "start_time": "2019-11-18T09:22:10.912Z"
    }
   },
   "outputs": [],
   "source": [
    "as.numeric(attributes(which.min(CVerr))$names)\n",
    "tree.reg=rpart(O3obs~.,data=datappr,control=rpart.control(cp=as.numeric(attributes(which.min(CVerr))$names)))\n",
    "rpart.plot(tree.reg,type=5,extra=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `partykit` library proposes a graphical construction of the tree : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.731129Z",
     "start_time": "2019-11-18T09:22:11.150Z"
    }
   },
   "outputs": [],
   "source": [
    "library(partykit)\n",
    "plot(as.party(tree.reg), type=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The window is too small to show the distributions (histogram) of the target variable (ozone concentration) in each sheet. \n",
    "\n",
    "**Question** Which variable contributes the most to the interpretation?\n",
    "\n",
    "Residuals plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.831850Z",
     "start_time": "2019-11-18T09:22:11.369Z"
    }
   },
   "outputs": [],
   "source": [
    "fit.tree=predict(tree.reg)\n",
    "res.tree=fit.tree-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.tree,res.tree,\"residus de tree.reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** To what is due the particular structure of this graph ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of code to do this pruning with the `caret` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method = \"cv\",number = 10)\n",
    "treecaret <- train(O3obs~.,data=datappr,method = \"rpart\",trControl = ctrl,tuneLength =20)\n",
    "print(paste(\"Valeur de cp retenue = \",treecaret$bestTune,sep=\"\"))\n",
    "rpart.plot(treecaret$finalModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation and pruning of a discrimination tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of discrimination, the default criterion is the Gini concentration index; it is possible to specify another criterion (split=\"information\") as well as weights on the observations, a misclassification cost matrix and a priori probabilities (`?rpart` for more details).\n",
    "\n",
    "**Question** What other heterogeneity criterion is used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.936071Z",
     "start_time": "2019-11-18T09:22:12.009Z"
    }
   },
   "outputs": [],
   "source": [
    "tree.dis=rpart(DepSeuil~.,data=datappq,parms=list(split=\"information\"),cp=0.001)\n",
    "rpart.plot(tree.dis) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same cross-validation pruning procedure is implemented but with a different expression of the prediction error : misclassification rate rather than squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:47.989031Z",
     "start_time": "2019-11-18T09:22:12.228Z"
    }
   },
   "outputs": [],
   "source": [
    "xmat = xpred.rpart(tree.dis)\n",
    "# Comparison of predicted and observed values\n",
    "xerr=datappq$DepSeuil!= (xmat>1.5) \n",
    "# Estimation of the error rate\n",
    "CVerr=apply(xerr, 2, sum)/nrow(xerr)\n",
    "CVerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.218396Z",
     "start_time": "2019-11-18T09:22:12.241Z"
    }
   },
   "outputs": [],
   "source": [
    "tree.dis=rpart(DepSeuil~.,data=datappq,parms=list(split=\"information\"),cp=as.numeric(attributes(which.min(CVerr))$names))\n",
    "rpart.plot(tree.dis,type=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `caret` library :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl <- trainControl(method = \"cv\",number = 10)\n",
    "treecaret <- train(DepSeuil~.,data=datappq,method = \"rpart\",trControl = ctrl,tuneLength =20,metric=\"Accuracy\")\n",
    "print(paste(\"Valeur de cp retenue = \",treecaret$bestTune,sep=\"\"))\n",
    "rpart.plot(treecaret$finalModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different predictions are considered along with the estimated errors on the test sample. Quantitative concentration prediction, exceedance prediction from the quantitative prediction and directly the exceedance prediction from the decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.248763Z",
     "start_time": "2019-11-18T09:22:12.672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Computation of the predictions\n",
    "pred.treer=predict(tree.reg,newdata=datestr)\n",
    "# Mean squared error in regression\n",
    "sum((pred.treer-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification error (confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.267073Z",
     "start_time": "2019-11-18T09:22:12.681Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for the prediction of \n",
    "# threshold overflow (regression)\n",
    "  #table(pred.treer>150,datestr[, \"O3obs\"]>150)\n",
    "confusionMatrix(as.factor(pred.treer>150),as.factor(datestr[,\"O3obs\"]>150))$table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.285260Z",
     "start_time": "2019-11-18T09:22:12.688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Same thing for the discrimination tree\n",
    "pred.treeq=predict(tree.dis,newdata=datestq,type=\"class\")\n",
    "  #table(pred.treeq,datestq[,\"DepSeuil\"])\n",
    "confusionMatrix(pred.treeq,datestq[,\"DepSeuil\"])$table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Which strategy seems better at this level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROCregtree=pred.treer/300\n",
    "predregtree=prediction(ROCregtree,datestq$DepSeuil)\n",
    "perfregtree=performance(predregtree,\"tpr\",\"fpr\")\n",
    "ROCdistree=predict(tree.dis,newdata=datestq,type=\"prob\")[,2]\n",
    "preddistree=prediction(ROCdistree,datestq$DepSeuil)\n",
    "perfdistree=performance(preddistree,\"tpr\",\"fpr\")\n",
    "# tracer les courbes ROC en les superposant \n",
    "# pour mieux comparer\n",
    "\n",
    "options(repr.plot.width = 8, repr.plot.height = 6)\n",
    "plot(perflogit,col=\"blue\")\n",
    "plot(perfregtree,col=\"orange\",lty=2,add=TRUE) \n",
    "plot(perfdistree,col=\"green\",add=TRUE)  \n",
    "\n",
    "legend(\"right\", legend=c(\"Logit\", \"TreeReg\", \"TreeDis\"),\n",
    "       col=c(\"blue\",\"orange\",\"green\"), lty=c(1,2,1), text.font=1,    cex=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Compare the predictive qualities. Does a better method emerge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Model Aggregation ](http://wikistat.fr/pdf/st-m-app-agreg.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The previous sections have allowed us to experiment with the construction of a forecasting model with the recurrent problem of optimizing the complexity of a model. This section discusses other strategies whose objective is to get rid of this problem of choice by methods that are not very sensitive to overlearning; this is the case of model aggregation algorithms.\n",
    "\n",
    "This section proposes to highlight the greater or lesser influence of the parameters of these methods.\n",
    "\n",
    "*Random forest* : number of trees and `mtry` and interest of Breiman criteria allowing to measure the influence of variables within an aggregated family of models. \n",
    "\n",
    "*Boosting*: tree depth, number of iterations or trees and *shrinkage* coefficient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests\n",
    "The program is available in the `randomForest` library. It is written in fortran, so in principle it is efficient in terms of speed of execution, and easy to use thanks to an interface with R. The comparison with Python shows that it is not very efficient, probably because of the interface with R. The parameters and outputs are explained in the online help.\n",
    "\n",
    "In R and for large files, use the `ranger` library instead of `randomForest`.\n",
    "\n",
    "**Question** What is the `mtry` parameter of the `randomForest` function?\n",
    "\n",
    "**Question** How is bagging a special case of random forests?\n",
    "\n",
    "Bagging will not be treated in this tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(randomForest)\n",
    "help(randomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf.reg=randomForest(O3obs~., data=datappr,xtest=datestr[,-2],ytest=datestr[,\"O3obs\"],\n",
    "   ntree=500,do.trace=50,importance=TRUE)\n",
    "attributes(rf.reg)\n",
    "rf.reg$mtry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is the default value of `mtry`?\n",
    "\n",
    "Rerun by varying the parameters `mtry` and `ntree` to experiment their little influence on the errors.\n",
    "\n",
    "Compute and plot the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.rfr=rf.reg$predicted\n",
    "res.rfr=fit.rfr-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.rfr,res.rfr,titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrimination\n",
    "**Question** What is the default value of `mtry`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.dis=randomForest(DepSeuil~.,data=datappq,xtest=datestq[,-10],ytest=datestq[,\n",
    "   \"DepSeuil\"],ntree=500,do.trace=50,importance=TRUE)\n",
    "rf.dis$importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.dis$mtry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Comment on the errors, test other runs with other parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Importance \n",
    "The resulting model is uninterpretable, but coefficients estimate the contributions of the variables in their participation in discrimination. Compare with the variables selected by the other models in episode 1. Two importance criteria are proposed.\n",
    "\n",
    "**Question** What are the two measures of importance of the variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort(round(importance(rf.reg), 2)[,1], decreasing=TRUE)\n",
    "sort(round(importance(rf.dis), 2)[,4], decreasing=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImpPlot(rf.reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImpPlot(rf.dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ggRandomForests)\n",
    "plot(gg_vimp(rf.reg))\n",
    "plot(gg_vimp(rf.dis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the test sample\n",
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forests\n",
    "pred.rfr=rf.reg$test$predicted\n",
    "# Mean squared error\n",
    "sum((pred.rfr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for the prediction of the threshold overflow (regression)\n",
    "table(pred.rfr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rfq=rf.dis$test$predicted\n",
    "table(pred.rfq,datestq[,\"DepSeuil\"])\n",
    "confusionMatrix(pred.rfq,datestq[,\"DepSeuil\"],positive=\"TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What does the comparison of the ROC curves indicate ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "Two libraries offer relatively sophisticated versions of *boosting* algorithms in R. The *boost* library offers 4 approaches: *adaboost, bagboost* and two *logitboost*. Developed for a particular problem: the analysis of genomic expression data, it may not be completely adapted to the data studied; it is limited to quantitative predictors and may provide strange results. The *gbm* library is preferred; it also offers several versions depending on the chosen cost function. A more recent library `xgboost` integrates parallelization features (not under Windows) and uses several other parameters.\n",
    "\n",
    "The variable to predict must be numerically coded (0-1) for this implementation. The number of iterations, or number of trees, is set as well as a shrinkage coefficient (*shrinkage*).\n",
    "\n",
    "**Question** How does *shrinkage* come into play in *boosting*? \n",
    "\n",
    "**Question** For which boosting? Or what does `gbm` mean?\n",
    "\n",
    "*Warning*, by default, this parameter has a very low value (0.001) and it takes a large number of iterations (of trees) to reach a reasonable estimate. The quality is visualized by a graph representing the evolution of the learning error. On the other hand, a cross-validation procedure is incorporated in order to optimize the number of trees because the version of *boosting* considered is (slightly) prone to over-learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class(ozone$STATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(gbm)\n",
    "boost.reg = gbm(O3obs ~ ., data = datappr, distribution = \"gaussian\", n.trees = 500, \n",
    "    cv.folds = 10, n.minobsinnode = 5, shrinkage = 0.03, verbose = FALSE)\n",
    "# set verbose to FALSE to avoid too many outputs\n",
    "plot(boost.reg$cv.error, type = \"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal number of iterations by cross-validation\n",
    "best.iter=gbm.perf(boost.reg,method=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ensure the absence of a critical overfitting phenomenon by calculating and plotting the evolution of the error on the test sample as a function of the number of trees in the model. The error remains stable around the number of trees selected and shown by the vertical line. \n",
    "\n",
    "**Question** Test these functions by varying the shrinkage coefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=numeric()\n",
    "for (i in 10:500){\n",
    "pred.test=predict(boost.reg,newdata=datestr,n.trees=i)\n",
    "err=sum((pred.test-datestr[,\"O3obs\"])^2)/nrow(datestr)\n",
    "test=c(test,err)}\n",
    "plot(10:500,test,type=\"l\")\n",
    "abline(v=best.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrimination\n",
    "Be careful, the variable to model must be coded $(0, 1)$ and another distribution parameter must be specified to consider the right error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datappq2=datappq\n",
    "datappq2[,\"DepSeuil\"]=as.numeric(datappq[,\"DepSeuil\"])-1\n",
    "boost.dis=gbm(DepSeuil~.,data=datappq2,distribution=\"adaboost\",n.trees=500, cv.folds=10,\n",
    "              n.minobsinnode = 5,shrinkage=0.03,verbose=FALSE)\n",
    "plot(boost.dis$cv.error,type=\"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal number of iterations\n",
    "best.ited=gbm.perf(boost.dis,method=\"cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the regression, it is possible to vary the shrinkage coefficient by associating it with the number of trees in the model.\n",
    "\n",
    "Computation of the residuals and graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.boostr=boost.reg$fit\n",
    "res.boostr=fit.boostr-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.boostr,res.boostr,titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the test sample \n",
    "#### Regression error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " pred.boostr=predict(boost.reg,newdata=datestr,n.trees=best.iter)\n",
    "#Mean squared error of prediction\n",
    "sum((pred.boostr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification error (confusion matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for prediction of threshold overflow (regression)\n",
    "table(pred.boostr>150,datestr[,\"O3obs\"]>150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same thing for discrimination\n",
    "pred.boostd=predict(boost.dis,newdata=datestq,n.trees=best.ited)\n",
    "table(as.factor(sign(pred.boostd)),datestq[,\"DepSeuil\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forests\n",
    "rocrfr=pred.rfr/300\n",
    "predrfr=prediction(rocrfr,datestq$DepSeuil)\n",
    "perfrfr=performance(predrfr,\"tpr\",\"fpr\")\n",
    "\n",
    "# Boosting\n",
    "rocbstr=pred.boostr/300\n",
    "predbstr=prediction(rocbstr,datestq$DepSeuil)\n",
    "perfbstr=performance(predbstr,\"tpr\",\"fpr\")\n",
    "\n",
    "# Roc curves\n",
    "plot(perflogit,col=\"blue\")\n",
    "plot(perfrfr,col=\"purple\",lty=2,add=TRUE)  \n",
    "plot(perfbstr,col=\"green\",add=TRUE) \n",
    "\n",
    "legend(\"right\", legend=c(\"Logit\",\"RF\", \"Boosting\"),\n",
    "       col=c(\"blue\",\"purple\",\"green\"), lty=c(1,2,1), text.font=1,    cex=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Which model aggregation strategy  provides the best prediction result? \n",
    "\n",
    "**Question** Is it, on this dataset, more efficient than the classical models tested before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Episode 4 : Neural networks </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Neural Networks](http://wikistat.fr/pdf/st-m-app-rn.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists in estimating a *perceptron* type model with qualitative or quantitative variables as input and the variable to be predicted as output. R functions for learning an elementary perceptron have been realized by different authors and are available on the network. The `nnet` library of (Ripley, 1999), is limited to the single layer perceptron. It is not \"deep learning\"! but it is sufficient in many cases. An R library associated with the eponymous H2O software proposes multi-layer and \"convolutional\" networks.\n",
    "\n",
    "As for trees, the variable to be explained is either quantitative or qualitative; the activation function of the output neuron of a network must be adapted accordingly. \n",
    "\n",
    "**Question** Which transfer function is used for the last neuron in regression? in binary classification? in multiclass classification? \n",
    "\n",
    "**Question** What is the default choice for the hidden layer neurons?\n",
    "\n",
    "Different strategies are proposed to avoid overfitting. The first one consists in optimizing the number of neurons on the hidden layer. Very roughly, it is usual to consider that, on average, we need a training sample size 10 times larger than the number of weights, i.e. the number of parameters to be estimated. We notice that here the training sample size (832) is modest for a reasonable application of the perceptron. Only a small number of neurons can be considered and on a single hidden layer. \n",
    "\n",
    "**Question** What is the `decay` parameter of the `nnet` function?\n",
    "\n",
    "**Question** What is another way to avoid overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:23:48.781644Z",
     "start_time": "2019-11-18T09:22:14.471Z"
    }
   },
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "library(nnet)\n",
    "# learning\n",
    "# beware of the parameter linout  in the regression case\n",
    "nnet.reg=nnet(O3obs~.,data=datappr,size=5,decay=1,linout=TRUE,maxit=500) \n",
    "summary(nnet.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command gives the \"trace\" of the execution with the convergence behavior but the detail of the weights of each input of each neuron is not a very explicit result! \n",
    "\n",
    "**Question** Check the number of estimated weights.\n",
    "\n",
    "The optimization of the parameters still requires  a cross-validation procedure. There is no function in the `nnet` library allowing to do this but the ` tune.nnet` function of the `e1071` library is adapted to this approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:00.187792Z",
     "start_time": "2019-11-18T09:22:14.679Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "plot(tune.nnet(O3obs~.,data=datappr,size=c(2,3,4),decay=c(1,2,3),maxit=200,linout=TRUE))\n",
    "plot(tune.nnet(O3obs~.,data=datappr,size=4:5,decay=1:10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually vary the parameter grid (zoom), note the optimal size and `decay`. You should also vary the total number of iterations. This might take a little time! Also note that each run gives different results... so it is not very useful to spend much time on it!\n",
    "\n",
    "**Question** Re-estimate the \"optimal\" model before plotting the residuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:00.436424Z",
     "start_time": "2019-11-18T09:22:14.895Z"
    }
   },
   "outputs": [],
   "source": [
    "nnet.reg=nnet(O3obs~.,data=datappr,size=3,decay=2,linout=TRUE,maxit=200)\n",
    "# computation and graph of the residuals\n",
    "fit.nnetr=predict(nnet.reg,data=datappr)\n",
    "res.nnetr=fit.nnetr-datappr[,\"O3obs\"]\n",
    "gplot.res(fit.nnetr,res.nnetr,titre=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrimination case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:00.463554Z",
     "start_time": "2019-11-18T09:22:15.102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "nnet.dis=nnet(DepSeuil~.,data=datappq,size=5,decay=0) \n",
    "summary(nnet.reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation is always necessary in order to try to optimize the choices in presence: number of neurons, `decay` and possibly the maximum number of iterations. \n",
    "\n",
    "The initialization of the training of a neural network as well as the estimation of the error by cross-validation are random. Each execution therefore gives different results. At this level, it would be interesting to build a two-factor design (here, the size and `decay` parameters) of each of the three levels. Several realizations for each combination of levels followed by a classical anova test would give a better idea of the influence of these factors on the error. \n",
    "\n",
    "**Question** Note the optimal size and `decay` and re-estimate the model for these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:25.823681Z",
     "start_time": "2019-11-18T09:22:15.309Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(tune.nnet(DepSeuil~.,data=datappq,size=c(3,4,5),decay=c(0,1,2),maxit=200,linout=FALSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:25.936811Z",
     "start_time": "2019-11-18T09:22:15.315Z"
    }
   },
   "outputs": [],
   "source": [
    "nnet.dis=nnet(DepSeuil~.,data=datappq,size=5,decay=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different predictions are considered along with the estimated errors on the test sample. Quantitative concentration prediction, exceedance prediction from the quantitative prediction and directly the exceedance prediction from the decision tree. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:25.972074Z",
     "start_time": "2019-11-18T09:22:15.713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Computation of the predictions\n",
    "pred.nnetr=predict(nnet.reg,newdata=datestr)\n",
    "pred.nnetq=predict(nnet.dis,newdata=datestq) \n",
    "#  Mean squared error\n",
    "sum((pred.nnetr-datestr[,\"O3obs\"])^2)/nrow(datestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification error (Confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:25.996337Z",
     "start_time": "2019-11-18T09:22:15.718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matrice de confusion pour la prévision du \n",
    "# dépassement de seuil (régression)\n",
    "table(pred.nnetr>150,datestr[,\"O3obs\"]>150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confusionMatrix(as.factor(pred.nnetr>150),as.factor(datestr[,\"O3obs\"]>150))$table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:26.022088Z",
     "start_time": "2019-11-18T09:22:15.725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Même chose pour la discrimination\n",
    "table(pred.nnetq>0.5,datestq[,\"DepSeuil\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:26.112355Z",
     "start_time": "2019-11-18T09:22:15.926Z"
    }
   },
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "\n",
    "\n",
    "roclogit <- predict(log.qm.step1, newdata = datestq, type=\"response\")\n",
    "predlogit <- prediction(roclogit, datestq[, \"DepSeuil\"])\n",
    "perflogit <- performance(predlogit, \"tpr\", \"fpr\")\n",
    "\n",
    "\n",
    "rocnnetr=pred.nnetr/300\n",
    "prednnetr=prediction(rocnnetr,datestq$DepSeuil)\n",
    "perfnnetr=performance(prednnetr,\"tpr\",\"fpr\")\n",
    "\n",
    "rocnnetq=pred.nnetq\n",
    "prednnetq=prediction(rocnnetq,datestq$DepSeuil)\n",
    "perfnnetq=performance(prednnetq,\"tpr\",\"fpr\")\n",
    "\n",
    "plot(perflogit,col=\"blue\")\n",
    "plot(perfnnetr,col=\"darkgreen\",lty=2,add=TRUE) \n",
    "plot(perfnnetq,col=\"darkgreen\",add=TRUE)  \n",
    "legend(\"right\", legend=c(\"Logit\", \"Nnetr\", \"Nnetq\"),\n",
    "       col=c(\"blue\",\"darkgreen\", \"darkgreen\"), lty=c(1,2,1), text.font=1,    cex=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Does one method seem significantly better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Episode 5 :  Industrialization of learning </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "One advantage of R is the large number of users who participate in the development of libraries. This advantage has a downside: the lack of homogeneity of the libraries. To remedy this in machine learning applications, the (meta)library [`caret`](https://topepo.github.io/caret/) of [Max Kuhn (2008)](https://www.jstatsoft.org/article/view/v028i05) integrates in a same usage, a same syntax, all the learning functionalities and proposes a unified approach of the parameter optimization procedures.\n",
    "\n",
    "The following instructions quickly repeat the previous steps in order to introduce the use of `caret`. They are limited to the objective of predicting threshold exceedance (classification). The code to model the concentration by regression is easily deduced.\n",
    "\n",
    "### Parallel calculation\n",
    "Moreover, even under Windows, `caret` simply offers parallelization possibilities by using the `doParallel` package. Even if the algorithms of the different learning methods are not parallelized, the iterations of the cross-validation computations for the optimization of the parameters are effectively parallelized with a very appreciable time saving depending on the number of processors. This is obtained by executing the following commands assuming that 4 processors are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:46.232486Z",
     "start_time": "2019-11-18T09:22:23.827Z"
    }
   },
   "outputs": [],
   "source": [
    "library(doParallel)\n",
    "cl <- makeCluster(4)\n",
    "registerDoParallel(cl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "The data considered are the initial data and the strategy adopted to optimize the models is the cross validation. Other choices are possible (bootstrap). The `caret` library integrates sampling and data normalization functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:46.260767Z",
     "start_time": "2019-11-18T09:22:24.051Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(ozone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:47.233193Z",
     "start_time": "2019-11-18T09:22:24.058Z"
    }
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "# extraction des données\n",
    "# Variable cible\n",
    "Y=ozone[,\"DepSeuil\"]\n",
    "# Variables explicatives\n",
    "X=ozone[,-c(2,11)]\n",
    "# Transformation des facteurs en indicatrices pour utiliser certains algorithmes\n",
    "# notamment xgboost\n",
    "library(FactoMineR)\n",
    "X=data.frame(tab.disjonctif(X[,c(1,4)]),X[,-c(1,4)])\n",
    "summary(Y);summary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:47.393572Z",
     "start_time": "2019-11-18T09:22:24.065Z"
    }
   },
   "outputs": [],
   "source": [
    "# indices  of the training sample\n",
    "xx=11 # this value can be changed \n",
    "set.seed(xx)\n",
    "inTrain = createDataPartition(X[,1],p = 0.8, list = FALSE)\n",
    "# Extraction of the samples\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "testY=Y[-inTrain]\n",
    "trainY=Y[inTrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some methods are sensitive to  the normalization the variables. It is preferable to introduce a normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:47.433813Z",
     "start_time": "2019-11-18T09:22:24.296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization calculated on the parameters of the training sample\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "# Then applied also to the test sample\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# Choice of cross-validation \n",
    "cvControl=trainControl(method=\"cv\",number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation of models\n",
    "The library includes many models or methods (233!) and those selected below are among the most used. See the [list of methods](http://topepo.github.io/caret/available-models.html) available as an option of the function: `train`.  The choice is normally limited to methods that accept both quantitative and qualitative variables, but by first transforming the qualitative variables into indicator packages (*dummies*) the other methods are accessible. Run each block of commands to plot each graph separately in order to check the good behavior of\n",
    "of the optimization of the complexity parameter of each model.\n",
    "\n",
    "The automation of the optimization of some methods such as logistic regression is less flexible than in \"manual\" use; in particular for the choice of the variable selection algorithm. It is necessary to be (very) patient for some optimizations while others are immediate, even useless. \n",
    "\n",
    "The `tuneLength` parameter characterizes an optimization \"effort\", it is roughly the number of parameter values tested on a grid set automatically. By taking more care and also more time, it is possible to precisely set grids for the optimized parameter values for each method. The basic `caret' approach is often sufficient and the optimization of a model, its complexity and can be refined after selection of the method.\n",
    "\n",
    "**Question** For each case, identify the method, specify the associated parameters and note the one or ones optimized by default by `caret`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:53.674471Z",
     "start_time": "2019-11-18T09:22:24.529Z"
    }
   },
   "outputs": [],
   "source": [
    "#1 Logistic Regression\n",
    "# Attention, the logistic regression without interaction (linear) is estimated below\n",
    "set.seed(2)\n",
    "rlogFit = train(trainDescr, trainY,method = \"glmStepAIC\", tuneLength = 10,\n",
    "                trControl = cvControl, trace=FALSE)\n",
    "rlogFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:25:54.874252Z",
     "start_time": "2019-11-18T09:22:24.537Z"
    }
   },
   "outputs": [],
   "source": [
    "#2 Decision tree\n",
    "set.seed(2)\n",
    "rpartFit = train(trainDescr, trainY, method = \"rpart\", tuneLength = 10,\n",
    "    trControl = cvControl)\n",
    "rpartFit\n",
    "plot(rpartFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:26:06.838240Z",
     "start_time": "2019-11-18T09:22:24.544Z"
    }
   },
   "outputs": [],
   "source": [
    "#3 Neural networks\n",
    "set.seed(2)\n",
    "nnetFit = train(trainDescr, trainY, method = \"nnet\", tuneLength = 6,\n",
    "                trControl = cvControl, trace=FALSE)\n",
    "nnetFit\n",
    "plot(nnetFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:26:19.223823Z",
     "start_time": "2019-11-18T09:22:24.551Z"
    }
   },
   "outputs": [],
   "source": [
    "#4 Random forest\n",
    "set.seed(2)\n",
    "rfFit = train(trainDescr, trainY,method = \"rf\", tuneLength = 8,\n",
    "              trControl = cvControl, trace=FALSE)\n",
    "rfFit\n",
    "plot(rfFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T09:26:28.217758Z",
     "start_time": "2019-11-18T09:22:24.558Z"
    }
   },
   "outputs": [],
   "source": [
    "#5 Boosting \n",
    "set.seed(2)\n",
    "gbmFit = train(trainDescr, trainY,method = \"gbm\", tuneLength = 8,\n",
    "               trControl = cvControl)\n",
    "gbmFit\n",
    "plot(gbmFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the *extreme gradient boosting* algorithm (gradient approximation by Taylor decomposition and code parallelization) is very present in the solutions of the *Kaggle* contests, it is tested. *Warning*, the good results of the competitions are obtained at the cost of a heavy and complex optimization procedure of the numerous parameters of this approach; procedure made possible by the advanced parallelization of the [`xgboost` library ](https://xgboost.readthedocs.io/en/latest/) and the use of graphic cards (GPU). If this environment is not available the optimization is quite long, even with parallelization on 4 processors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:24.804Z"
    }
   },
   "outputs": [],
   "source": [
    "#6 Extrême gradient boosting\n",
    "library(xgboost)\n",
    "set.seed(2)\n",
    "xgbFit = train(trainDescr, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl, trace=FALSE)\n",
    "xgbFit\n",
    "plot(xgbFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of the test sample\n",
    "The selected and optimized methods are then applied to the test sample. Estimation of the proportion of well classified :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:25.049Z"
    }
   },
   "outputs": [],
   "source": [
    "models=list(logit=rlogFit,cart=rpartFit,nnet=nnetFit,rf=rfFit,gbm=gbmFit,xgb=xgbFit)\n",
    "testPred=predict(models, newdata = testDescr)\n",
    "# roportion of well classified \n",
    "lapply(testPred,function(x)mean(x==testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drawing of ROC curves to analyze the specificity and sensitivity of the different methods.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:25.288Z"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "\n",
    "models=list(logit=rlogFit,cart=rpartFit,nnet=nnetFit,rf=rfFit,gbm=gbmFit,xgb=xgbFit)\n",
    "testProb=predict(models, newdata = testDescr,type=\"prob\")\n",
    "predroc=lapply(testProb,function(x)prediction(x[,1],testY==FALSE))\n",
    "perfroc=lapply(predroc,\n",
    "function(x)performance(x, \"tpr\", \"fpr\"))\n",
    "plot(perfroc$logit,col=1)\n",
    "plot(perfroc$cart,col=2,add=TRUE)\n",
    "plot(perfroc$nnet,col=3,add=TRUE)\n",
    "plot(perfroc$rf,col=4,add=TRUE)\n",
    "plot(perfroc$gbm,col=5,add=TRUE)\n",
    "plot(perfroc$xgb,col=6,add=TRUE)\n",
    "legend(\"bottomright\",legend=c(\"logit\",\"CART\",\"nnet\",\"RF\",\"boost\",\"xgBoost\"),col=c(1:6),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [*Monte Carlo* Cross-validation ](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf)\n",
    "The sample size is small (#200), and the estimates of the goodness-of-fit rates as well as the ROC curves are very dependent on the test sample; one can question the identity of the best performing model as well as the significance of the observed differences between the methods. It is therefore important to iterate the process (*Monte Carlo* cross validation) on several test samples. \n",
    "\n",
    "**Question** Run the function in the appendix by choosing the methods that seem to perform best. Beware of the computation time! CART can perform well and is deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:25.551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose the list of methods and the optimization effort\n",
    "models=c(\"gbm\",\"rf\",\"nnet\",\"glmStepAIC\",\"xgbTree\")\n",
    "noptim=c(6,6,6,6,6)\n",
    "# Initialize the generator and set the number of iterations\n",
    "# Change these values. Beware of the computation time! Be patient!\n",
    "\n",
    "Niter=10 ; \n",
    "Init=11  \n",
    "# Call the function defined in the appendix\n",
    "pred.ozone=pred.autom(X,Y,methodes=models,N=Niter,xinit=Init,size=noptim,type=\"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:25.800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculation of well classified rates\n",
    "obs=pred.ozone$obs\n",
    "prev.ozone=pred.ozone$pred\n",
    "res.ozone=lapply(prev.ozone,function(x)apply((x>0.5)==(obs==1),2,mean))\n",
    "# Average rates of well classified by method\n",
    "lapply(res.ozone,mean)\n",
    "# distributions of well classified rates\n",
    "boxplot(data.frame(res.ozone))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivantes tracent les courbes ROC moyennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:26.055Z"
    }
   },
   "outputs": [],
   "source": [
    "## Comparison of the methods by\n",
    "# plotting the mean ROC curves\n",
    "# \n",
    "predroc.ozone=lapply(prev.ozone,function(x)prediction(x,obs==1))\n",
    "perfroc.ozone=lapply(predroc.ozone,function(x)performance(x,\"tpr\",\"fpr\"))\n",
    "plot(perfroc.ozone$gbm,col=1,lwd=2,avg=\"vertical\")\n",
    "plot(perfroc.ozone$rf,col=2,add=TRUE,lwd=2,avg=\"vertical\")\n",
    "plot(perfroc.ozone$nnet,add=TRUE,col=3,lwd=1.5,avg=\"vertical\")\n",
    "plot(perfroc.ozone$xgbTree,add=TRUE,col=4,lwd=1.5,avg=\"vertical\")\n",
    "plot(perfroc.ozone$glmStepAIC,add=TRUE,col=5,lwd=1.5,avg=\"vertical\")\n",
    "legend(\"bottomright\",legend=c(\"boost\",\"RF\", \"nnet\",\"xgBoost\",\"logit\"),col=c(1:5),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What method should be used, based on the acceptable false positive rate, to predict when the threshold will be exceeded? What if the client wants an explainable solution?\n",
    "\n",
    "The same approach performed on the concentration prediction before predicting the threshold exceedance leads to similar results. \n",
    "\n",
    "*N.B.* \n",
    "* It is not the logistic regression with interactions (quadratic) that has been tested in this last comparison.\n",
    "* The xgboost algorithm would require more effort to optimize the parameters, but the computational cost is lower. To be tested in Python with an access to a GPU card."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Episode 6 : Missing data management </font> \n",
    "**Note** It is possible to run *episode 6* directly without going through all the supervised classification steps. It is sufficient to run *sections 2 and 3* of *episode 1*, the exploratory phase, in order to build the data used in sections 13 and 14 of imputation of missing data and detection of atypicals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Missing data management](http://wikistat.fr/pdf/st-m-app-idm.pdf)\n",
    "\n",
    "Real data are most often affected by missing data, due to input errors, sensor failures... The R libraries offer many choices for imputing missing data when it is completely random. \n",
    "\n",
    "Several strategies are executed and compared after having randomly generated a percentage of failures (holes) in the values of the explanatory variables.\n",
    "\n",
    "**Question** Why does the structure of the explanatory variables lead to the execution of the missForest algorithm of the eponymous library? \n",
    "\n",
    "**In a first step**, we will compare some imputation methods on quantitative explanatory data: LOCF, imputation by the mean or the median, kNN, missForest and Amelia II.\n",
    "\n",
    "\n",
    "**In a second step**, we will focus on the Missforest method and the objective will be to study the impact of the data imputation on the classification performance for predicting the \"threshold crossing\" variable by comparing two strategies:\n",
    "\n",
    "\n",
    "The **first strategy** starts by imputing the missing data by predicting them by the MissForest algorithm. \n",
    "\n",
    "Once the missing data is imputed, different forecasting methods can be used as before. Two are executed: random forests and *extrem gradient boosting*.\n",
    "\n",
    "The **second strategy** avoids the imputation step by directly running a missing data tolerant forecasting algorithm. Few algorithms do this, it is the case of `XGBoost`.\n",
    "\n",
    "Beware, the commands below call for many files that are easy to mix up.\n",
    "- X` the initial complete data and `Xd` the version where categorical variables are replaced by indicators, \n",
    "- `Xna` the data with holes, `Xdna` the version with indicators,\n",
    "\n",
    "- `XnaImp` the data with imputations and `XdnaImp` the version with indicators.\n",
    "\n",
    "The replacement of categorical variables by indicator variables is imposed by the use of the `XGBoost` library and it does not change the results of the random forests.\n",
    "\n",
    "### Preparing the missing values in Ozone data\n",
    "The initial data of the `ozone` database are used. Only the variable to explain the threshold crossing is kept. The `missForest` library proposes a function to generate a fixed percentage of missing data in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:26.834Z"
    }
   },
   "outputs": [],
   "source": [
    "# Target Variable\n",
    "Y=ozone[,\"DepSeuil\"]\n",
    "# Explanatory Variables \n",
    "X=ozone[,-c(2,11)]\n",
    "n=nrow(X); p=ncol(X)\n",
    "summary(Y); summary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:26.842Z"
    }
   },
   "outputs": [],
   "source": [
    "library(missForest)\n",
    "# make a proportion of NA  in X\n",
    "# data missing at random\n",
    "tauxNa=0.2\n",
    "set.seed(11)\n",
    "Xna=prodNA(X,tauxNa)\n",
    "summary(Xna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is the average number of missing data per column?\n",
    "\n",
    "### Comparing imputation methods on quantitative data ###\n",
    "\n",
    "We keep only the quantitative variables to compare various imputation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table of quantitative data\n",
    "#Comparison of the different completion methods on the variable Temperature\n",
    "\n",
    "Xnaquanti=Xna[,-c(1,4)]\n",
    "Xquanti=X[,-c(1,4)]\n",
    "ind.na=which(is.na(Xnaquanti),arr.ind=TRUE)\n",
    "ind.na.Temp=which(is.na(Xnaquanti[,2]),arr.ind=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completion with the last known value (LOCF) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(zoo) \n",
    "X.locf=na.locf(Xnaquanti,na.rm=FALSE)\n",
    "X.locf=na.locf(X.locf,na.rm=FALSE,fromLast=TRUE) # dans l'autre sens\n",
    "err.locf=(Xquanti-X.locf)[ind.na.Temp,2]\n",
    "boxplot(err.locf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completion by the mean ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "moy=apply(Xnaquanti,2,mean,na.rm=TRUE)\n",
    "X.moy=Xnaquanti\n",
    "ind.na=which(is.na(X.moy),arr.ind=TRUE)\n",
    "X.moy[ind.na]=moy[ind.na[,2]]\n",
    "err.moy=(Xquanti-X.moy)[ind.na.Temp,2]\n",
    "boxplot(data.frame(err.locf,err.moy),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completion by the median ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "med=apply(Xnaquanti,2,median,na.rm=TRUE)\n",
    "X.med=Xnaquanti\n",
    "ind.na=which(is.na(X.med),arr.ind=TRUE)\n",
    "X.med[ind.na]=med[ind.na[,2]]\n",
    "err.med=(Xquanti-X.med)[ind.na.Temp,2]\n",
    "\n",
    "boxplot(data.frame(err.locf,err.moy,err.med),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completion by k nearest neighbours (kNN) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(VIM) \n",
    "X.kNN=kNN(Xnaquanti, k=5, imp_var=FALSE)\n",
    "err.kNN=(Xquanti-X.kNN)[ind.na.Temp,2]\n",
    "boxplot(data.frame(err.locf,err.moy,err.med,err.kNN),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completion with Missforest ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X.mf=missForest(Xnaquanti,xtrue=Xquanti)\n",
    "err.mf=(Xquanti-X.mf$ximp)[ind.na.Temp,2]\n",
    "boxplot(data.frame(err.locf,err.moy,err.med,err.kNN,err.mf),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completion with Amelia II ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(Amelia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.amelia=amelia(Xnaquanti,m=1)$imputations$imp1\n",
    "err.amelia=(Xquanti-X.amelia)[ind.na.Temp,2]\n",
    "boxplot(data.frame(err.locf,err.moy,err.med,err.kNN,err.mf,err.amelia),ylim=c(-15,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What do you conclude? Which method seems to you the most relevant on these data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation with MissForest and impact on classification ###\n",
    "\n",
    "The complete dataset, including the quantitative explanatory variables, is used here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing the \"true\" initial data, it is possible, in this case, to compute `missForest' imputation errors.\n",
    "\n",
    "**Question** What are they? What estimate of error is provided when the missing data are really missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(missForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.103Z"
    }
   },
   "outputs": [],
   "source": [
    "XnaImp=missForest(Xna,xtrue=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.111Z"
    }
   },
   "outputs": [],
   "source": [
    "XnaImp$OOBerror;XnaImp$error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the allocations are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.381Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(XnaImp$ximp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the use of `XGBoost` requires transforming the factors into indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.648Z"
    }
   },
   "outputs": [],
   "source": [
    "library(FactoMineR)\n",
    "# complete data\n",
    "Xd=data.frame(tab.disjonctif(X[,c(1,4)]),X[,-c(1,4)])\n",
    "# data with missing values\n",
    "Xdna=data.frame(tab.disjonctif(Xna[,c(1,4)]),Xna[,-c(1,4)]) \n",
    "# data with imputations\n",
    "XdnaImp=data.frame(tab.disjonctif(XnaImp$ximp[,c(1,4)]),XnaImp$ximp[,-c(1,4)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `caret` library makes the syntax for running `xgboost` much easier, so it is included. Otherwise you would have to transform the data into another format. This is integrated by `caret`.\n",
    "\n",
    "Construction of the same learning and test samples in the three cases: initial, missing and imputed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.913Z"
    }
   },
   "outputs": [],
   "source": [
    "library(caret)\n",
    "# parallelisation\n",
    "library(doParallel)\n",
    "cl <- makeCluster(4)\n",
    "registerDoParallel(cl) \n",
    "# indicesof the training sample\n",
    "xx=11 # Change this value to customize the sampling\n",
    "set.seed(xx)\n",
    "inTrain = createDataPartition(X[,1],p = 0.8, list = FALSE)\n",
    "# Sample extraction\n",
    "trainDescr=Xd[inTrain,]\n",
    "testDescr=Xd[-inTrain,]\n",
    "# the sames with missing values\n",
    "trainDescrNA=Xdna[inTrain,]\n",
    "testDescrNA=Xdna[-inTrain,]\n",
    "# the sames with imputed missing values\n",
    "trainDescrNAimp=XdnaImp[inTrain,]\n",
    "testDescrNAimp=XdnaImp[-inTrain,]\n",
    "testY=Y[-inTrain]\n",
    "trainY=Y[inTrain]\n",
    "cvControl=trainControl(method=\"cv\",number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction with random forest on the initial data\n",
    "set.seed(2)\n",
    "rfFit = train(trainDescr, trainY,method = \"rf\", tuneLength = 8,\n",
    "              trControl = cvControl, trace=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:27.928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction with XGBoost on the initial data\n",
    "\n",
    "set.seed(2)\n",
    "xgbFit = train(trainDescr, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `XGBoost` is running, review the [principles of this algorithm](http://wikistat.fr/pdf/st-m-app-agreg.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.205Z"
    }
   },
   "outputs": [],
   "source": [
    "# prediction error on the test with initial data\n",
    "models=list(rf=rfFit,xgb=xgbFit)\n",
    "testPred=predict(models, newdata = testDescr)\n",
    "# Well clasified rate\n",
    "lapply(testPred,function(x)mean(x==testY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.212Z"
    }
   },
   "outputs": [],
   "source": [
    "# prediciton with random forest on imputed data\n",
    "set.seed(2)\n",
    "rfFitNAimp = train(trainDescrNAimp, trainY,method = \"rf\", tuneLength = 8,\n",
    "              trControl = cvControl, trace=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.220Z"
    }
   },
   "outputs": [],
   "source": [
    " # prediction with XGBoost on imputed data\n",
    "\n",
    "xgbFitNAimp = train(trainDescrNAimp, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `XGBoost` is running, revise the [principes of missForest](http://wikistat.fr/pdf/st-m-app-idm.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.506Z"
    }
   },
   "outputs": [],
   "source": [
    "# prediction error on the test with imputed data\n",
    "\n",
    "models=list(rfNAimp=rfFitNAimp,xgbNAimp=xgbFitNAimp)\n",
    "\n",
    "testPred=predict(models, newdata = testDescrNAimp)\n",
    "# Well classified rate\n",
    "lapply(testPred,function(x)mean(x==testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What do you conclude about the quality of the results after imputation? Increase the rate of missing data to see the impact of this rate on the prediction quality. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting without imputation \n",
    "\n",
    "The imputation phase is made mandatory by the use of many methods that do not accept missing data. It can be interesting to do without it because the reconstructed information is not usable for other purposes; `XGBoost` offers this oppotunity. While it is running, [try to understand](https://arxiv.org/abs/1603.02754) the tricks implemented to tolerate missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction with XGBoost with missing data\n",
    "\n",
    "xgbFitNA = train(trainDescrNA, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-18T09:22:28.793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prediction error with XGBoot tolerating missing data\n",
    "testPred=predict(xgbFitNA, newdata = testDescrNA)\n",
    "mean(testPred==testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** Compare the results obtained by the different strategies. Taking into account the computation time, which one seems to be the most efficient on this data. \n",
    "\n",
    "*NB* The advanced use of `XGBoost` requires more computational power in order to fine tune the many parameters.\n",
    "\n",
    "**Question** What would happen if we used Python instead of R?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: *Monte Carlo* cross-validation function\n",
    "*N* replications of estimates / forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.autom=function(X,Y,p=1/2,methodes=c(\"knn\",\n",
    "\"rf\"),size=c(10,2),xinit=11,N=10,typerr=\"cv\",\n",
    "number=4,type=\"raw\") {\n",
    "# Prediction function for N test samples\n",
    "# by a list of regression methods\n",
    "# or classification (only 2 classes)\n",
    "# Optimization of parameters by validation\n",
    "# cross validation (default) or bootstrap or... (cf. caret)\n",
    "# X: matrix or frame of explanatory variables\n",
    "# Y: quantitative or qualitative target variable\n",
    "# p : proportion between learning and testing\n",
    "# methods : list of discrimination methods\n",
    "# size : a grid of the parameters to be optimized\n",
    "# xinit : random number generator\n",
    "# N : number of learning/test replications\n",
    "# typerr : \"cv\" or \"boo\" or \"oob\n",
    "# number : number of CV or bootstrap replications\n",
    "# pred : list of prediction matrices\n",
    "# error type\n",
    "Control=trainControl(method=typerr,number=number)\n",
    "# initialisation of the generator\n",
    "set.seed(xinit)\n",
    "# list of matrices storing the forecasts\n",
    "# one per method\n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "ntest=length(Y[-inTrain])\n",
    "pred=vector(\"list\",length(methodes))\n",
    "names(pred)=methodes\n",
    "pred=lapply(pred,function(x)x=matrix(0,\n",
    "nrow=ntest,ncol=N))\n",
    "obs=matrix(0,ntest,N)\n",
    "set.seed(xinit)\n",
    "for(i in 1:N) {\n",
    "# N iterations\n",
    "# indices of the training sample\n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "# Sample extraction\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "trainY=Y[inTrain]\n",
    "testY=Y[-inTrain]\n",
    "# storage of test observations Y\n",
    "obs[,i]=testY\n",
    "# centering and reduction of variables\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# estimation and optimization of models\n",
    "# for each method in the list\n",
    "for(j in 1:length(methodes)) {\n",
    "# modelisation\n",
    "modFit = train(trainDescr, trainY,method = methodes[j], tuneLength = size[j],\n",
    "               trControl = Control)\n",
    "# previsions\n",
    "if (type==\"prob\")  pred[[j]][,i]=predict(modFit,\n",
    "newdata = testDescr,type=type)[,1]\n",
    "else pred[[j]][,i]=predict(modFit,\n",
    "newdata = testDescr)\n",
    "}}\n",
    "list(pred=pred,obs=obs)\n",
    "# results\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {
    "height": "630.933px",
    "left": "33px",
    "right": "1081.6px",
    "top": "107.133px",
    "width": "153px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
